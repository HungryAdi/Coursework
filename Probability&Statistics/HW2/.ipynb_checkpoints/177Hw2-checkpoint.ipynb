{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 177 HW 2\n",
    "### Aditya Iyer - 24377286\n",
    "\n",
    "## Problem 1\n",
    "### a)\n",
    "* expected number of disk failures in one year = E[X]\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "n = 3\\\\\n",
    "k = 2\\\\\n",
    "P(1 disk fail) = p\\\\\n",
    "E[x] = np\\\\\n",
    "E[X] = 3p\\\\\n",
    "P(functioning) = P(X>=2) = P(X=2) + P(X=3)\\\\\n",
    "P(X>=2) = \\binom{3}{2}*p^2(1-p)^1 + \\binom{3}{3}p^3(1-p)^0\\\\\n",
    "P(functioning) = (3*p^2(1-p)) + p^3\\\\\n",
    "P(functioning) = (3p^2 - 3p^3) + p^3\\\\\n",
    "P(functioning) = 3p^2 - 2p^3\n",
    "\\end{eqnarray*}\n",
    "\n",
    "### b)\n",
    "* expected number of disk failures in one year = E[X]\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "n = 5\\\\\n",
    "k = 3\\\\\n",
    "P(1 disk fail) = p\\\\\n",
    "E[x] = np\\\\\n",
    "E[X] = 5p\\\\\n",
    "P(functioning) = P(X>=3) = P(X=3) + P(X=4) + P(X=5)\\\\\n",
    "P(functioning) = \\binom{5}{3}*p^3(1-p)^2 + \\binom{5}{4}*p^4(1-p)^1 + \\binom{5}{5}*p^5(1-p)^0\\\\\n",
    "P(functioning) = (10p^3(1-p)^2) + (5p^4(1-p)) + p^5\\\\\n",
    "\\end{eqnarray*}\n",
    "\n",
    "### c)\n",
    "* Suppose p = 0.1\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "a) = 3(0.1)^2 - 2(0.1)^3\\\\\n",
    "a) = 0.028\\\\\n",
    "b) = (10(0.1)^3(1-0.1)^2) + (5(0.1)^4(1-(0.1))) + (0.1)^5\\\\\n",
    "b) = 0.00856\\\\\n",
    "\\end{eqnarray*}\n",
    "\n",
    "* Since a > b, the system described in a) is a more reliable system\n",
    "\n",
    "### d)\n",
    "* Suppose p = 0.6\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "a) = 3(0.6)^2 - 2(0.6)^3\\\\\n",
    "a) = 0.648\\\\\n",
    "b) = (10(0.6)^3(1-0.6)^2) + (5(0.6)^4(1-(0.6))) + (0.6)^5\\\\\n",
    "b) = 0.68256\\\\\n",
    "\\end{eqnarray*}\n",
    "\n",
    "* Since b > a, the system described in b) is a more reliable system\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "### a)\n",
    "* Expected payoff of single roll:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\frac{1+2+3+4+5}{5}*P(1,2,3,4,5)\\\\\n",
    "=\\frac{15}{5}*\\frac{5}{6}\\\\\n",
    "\\end{eqnarray*}\n",
    "\n",
    "* Expected payoff of multiple rolls:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "n*3(\\frac{5}{6})^n\\\\\n",
    "\\end{eqnarray*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f93c10f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def do_payoff(n):\n",
    "    return (n*3*((5/6)**n))\n",
    "\n",
    "n = []\n",
    "func_arr = []\n",
    "for i in range(20):\n",
    "    n.append(i+1)\n",
    "    func_arr.append(do_payoff(i+1))\n",
    "plt.plot(n,func_arr,'bo',label=\"Expected Payoff\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smallest value that maximizes payoff is n = 6\n",
    "\n",
    "### b)\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "E[X] = E[\\sum\\limits_{i=1}^6X]\\\\\n",
    "E[X] = \\sum\\limits_{i=1}^6P(distinct)\\\\\n",
    "E[X] = \\sum\\limits_{i=1}^6 (1-(\\frac{5}{6})^n)\\\\\n",
    "E[X] = 6-(\\frac{5}{6})^n\\\\\n",
    "E[X] = 6-0.1615\\\\\n",
    "E[X] = 5.8385\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "### a)\n",
    "\\begin{eqnarray*}\n",
    "P(C=1) = 0 + 0.1 + 0.05 + 0.25\\\\\n",
    "P(C=1) = 0.4\\\\\n",
    "\\end{eqnarray*}\n",
    "\n",
    "### b)\n",
    "\\begin{eqnarray*}\n",
    "P(C=0|X=1,Y=0) = P(C=0,X=1,Y=0)/P(X=1,Y=0)\\\\\n",
    "P(C=0|X=1,Y=0) = 0.2/(0.2+0.05)\\\\\n",
    "P(C=0|X=1,Y=0) = 0.2/0.25\\\\\n",
    "P(C=0|X=1,Y=0) = 0.8\n",
    "\\end{eqnarray*}\n",
    "\n",
    "### c)\n",
    "\\begin{eqnarray*}\n",
    "P(X=0,Y=0) = 0.1 + 0.0\\\\\n",
    "P(X=0,Y=0) = 0.1\\\\\n",
    "\\end{eqnarray*}\n",
    "\n",
    "### d)\n",
    "\\begin{eqnarray*}\n",
    "P(C=0|X=0) = P(C=0,X=0)/P(X=0)\\\\\n",
    "P(C=0|X=0) = (0.1+0.2)/(0.1+0.2+0+0.1)\\\\\n",
    "P(C=0|X=0) = 0.3/0.4\\\\\n",
    "P(C=0|X=0) = 0.75\\\\\n",
    "\\end{eqnarray*}\n",
    "\n",
    "### e)\n",
    "* If X and Y are independent...\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "P(X|Y) = P(X)P(Y)\\\\\n",
    "P(X)*P(Y) = (0.2+0.1+0.05+0.25)(0.2+0.1+0.1+0.25)\\\\\n",
    "P(X)*P(Y) = (0.6)(0.65)\\\\\n",
    "P(X)*P(Y) = 0.39\\\\\n",
    "P(X|Y) = P(X,Y)/P(Y)\\\\\n",
    "P(X|Y) = (0.1+0.25)/0.65\\\\\n",
    "P(X|Y) = 0.35/0.65\\\\\n",
    "P(X|Y) = 0.538\\\\\n",
    "P(X|Y) != P(X)P(Y)\\\\\n",
    "\\end{eqnarray*}\n",
    "\n",
    "* Therefore X and Y are NOT independent\n",
    "\n",
    "### f)\n",
    "* If X and Y are conditionally independent...\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "P(X,Y|C) = P(X|C)P(Y|C)\\\\\n",
    "P(X,Y|C) = \\frac{P(X,C)}{P(C)}*\\frac{P(Y,C)}{P(C)}\\\\\n",
    "P(X,Y|C) = \\frac{0.3}{0.4}*\\frac{0.35}{0.4}\\\\\n",
    "P(X,Y|C) = 0.75*0.875\\\\\n",
    "P(X,Y|C) = 0.6562\\\\\n",
    "\\end{eqnarray*}\n",
    "\n",
    "* If X and Y are not conditionally independent...\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "P(X,Y|C) = \\frac{P(X,Y,C)}{P(C)}\\\\\n",
    "P(X,Y|C) = \\frac{0.25}{0.4}\\\\\n",
    "P(X,Y|C) = 0.625\\\\\n",
    "\\end{eqnarray*}\n",
    "\n",
    "* Therefore, X and Y are NOT condionally independednt\n",
    "\n",
    "## Problem 4\n",
    "### a)\n",
    "\\begin{eqnarray*}\n",
    "P(Y=S|X) > P(Y=H|X)\\\\\n",
    "P(Y=S,X)/P(X) > P(Y=H,X)/P(X)\\\\\n",
    "P(Y=S,X) > P(Y=H,X)\\\\\n",
    "P(X|Y=S)P(Y=S) > P(X|Y=H)P(Y=H)\\\\\n",
    "(1):P(Y=S) = P(Y=H) = 0.5\\\\\n",
    "P(X|Y=S)0.5 > P(X|Y=H)0.5\\\\\n",
    "P(X|Y=S) > P(X|Y=H)\\\\\n",
    "\\end{eqnarray*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "\n",
    "def load_data():\n",
    "    data = loadmat('enron.mat')\n",
    "    trainFeat = np.array(data['trainFeat'], dtype=bool)\n",
    "    trainLabels = np.squeeze(data['trainLabels'])\n",
    "    testFeat = np.array(data['testFeat'], dtype=bool)\n",
    "    testLabels = np.squeeze(data['testLabels'])\n",
    "    vocab = np.squeeze(data['vocab'])\n",
    "    vocab = [vocab[i][0].encode('ascii', 'ignore') for i in range(len(vocab))]\n",
    "    data = dict(trainFeat=trainFeat, trainLabels=trainLabels,\n",
    "                testFeat=testFeat, testLabels=testLabels, vocab=vocab)\n",
    "    return data\n",
    "\n",
    "# Load data\n",
    "data = load_data()\n",
    "trainFeat = data['trainFeat']\n",
    "trainLabels = data['trainLabels']\n",
    "testFeat = data['testFeat']\n",
    "testLabels = data['testLabels']\n",
    "vocab = data['vocab']\n",
    "W = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Display words that are common in one class, but rare in the other\\nind = np.argsort(countsHam-countsSpam)\\nprint('Words common in Ham but not Spam:')\\nfor i in range(-1, -100, -1):\\n    print(vocab[ind[i]])\\n#print\\nprint('Words common in Spam but not Ham:')\\n#for i in range(100):\\n   # print(vocab[ind[i]])\\n\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Data description:\n",
    "    - trainFeat: (Dtrain, W) logical 2d-array of word appearance for training documents.\n",
    "    - trainLabels: (Dtrain,) 1d-array of {0,1} training labels where 0=ham, 1=spam.\n",
    "    - testFeat: (Dtest, W) logical 2d-array of word appearance for test documents.\n",
    "    - testLabels:  (Dtest,) 1d-array of {0,1} test labels where 0=ham, 1=spam.\n",
    "    - vocab: (W,) 1d-array where vocab[i] is the English characters for word i.\n",
    "'''\n",
    "\n",
    "# Different possible vocabularies to use in classification, uncomment chosen line\n",
    "#vocabInds =  179  # Part (c): \"money\"\n",
    "#vocabInds =  859  # Part (d): \"thanks\"\n",
    "#vocabInds = 2211  # Part (e): \"possibilities\"\n",
    "#vocabInds = [179, 859, 2211]  # Part (f): \"money\", \"thanks\", & \"possibilities\"\n",
    "vocabInds = np.arange(W)  # Part (g): full vocabularly of all W words\n",
    "\n",
    "# Separate \"ham\" and \"spam\" classes, subsample selected vocabulary words\n",
    "trainHam  = trainFeat[trainLabels == 0][:, vocabInds]\n",
    "trainSpam = trainFeat[trainLabels == 1][:, vocabInds]\n",
    "\n",
    "# Number of training examples of each class\n",
    "numHam = len(trainHam)\n",
    "numSpam = len(trainSpam)\n",
    "\n",
    "# Count number of times each word occurs in each class\n",
    "countsHam = np.sum(trainHam, axis=0)\n",
    "# P(X_ij=1 | Y_i=H) can be computed from countsHam and numHam\n",
    "countsSpam = np.sum(trainSpam, axis=0)\n",
    "# P(X_ij=1 | Y_i=S) can be computed from countsSpam and numSpam\n",
    "\n",
    "'''\n",
    "# Display words that are common in one class, but rare in the other\n",
    "ind = np.argsort(countsHam-countsSpam)\n",
    "print('Words common in Ham but not Spam:')\n",
    "for i in range(-1, -100, -1):\n",
    "    print(vocab[ind[i]])\n",
    "#print\n",
    "print('Words common in Spam but not Ham:')\n",
    "#for i in range(100):\n",
    "   # print(vocab[ind[i]])\n",
    "'''\n",
    "#print(countsHam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeProbabilities():\n",
    "    PwordGivenSpam = countsSpam/numSpam\n",
    "    PwordGivenHam = countsHam/numHam\n",
    "    PNotwordGivenSpam = (numSpam - countsSpam)/numSpam\n",
    "    PNotwordGivenHam = (numHam - countsHam)/numHam\n",
    "    return (PwordGivenSpam,PwordGivenHam,PNotwordGivenSpam,PNotwordGivenHam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of 'money' given target Spam: 0.16414288487672296\n",
      "Probability of 'money' given target Ham: 0.030321345824518987\n",
      "\n",
      "Classifier test accuracy: 0.08170225385527877\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "PwordSpam, PwordHam, _, _ = computeProbabilities()\n",
    "print(\"Probability of 'money' given target Spam: {}\".format(PwordSpam))\n",
    "print(\"Probability of 'money' given target Ham: {}\\n\".format(PwordHam))\n",
    "\n",
    "for i in range(len(testFeat)):\n",
    "    if (testFeat[i][179] == 1):\n",
    "        if (testLabels[i] == 1):\n",
    "            accuracy += 1\n",
    "accuracy /= len(testFeat)\n",
    "print(\"Classifier test accuracy: {}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of 'thanks' given target Spam: 0.06853038245000971\n",
      "Probability of 'thanks' given target Ham: 0.32013700010073537\n",
      "\n",
      "Classifier test accuracy: 0.15732502965599052\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "PwordSpam, PwordHam, _, _ = computeProbabilities()\n",
    "print(\"Probability of 'thanks' given target Spam: {}\".format(PwordSpam))\n",
    "print(\"Probability of 'thanks' given target Ham: {}\\n\".format(PwordHam))\n",
    "\n",
    "for i in range(len(testFeat)):\n",
    "    if (testFeat[i][859] == 1):\n",
    "        if (testLabels[i] == 0):\n",
    "            accuracy += 1\n",
    "accuracy /= len(testFeat)\n",
    "print(\"Classifier test accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a difference in classifier accuracy from c to d given the difference in frequency of the words 'thanks' and 'money' in the training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of 'possibilities' given target Spam: 0.0025237817899437004\n",
      "Probability of 'possibilities' given target Ham: 0.0025183842046942683\n",
      "\n",
      "Classifier test accuracy: 0.035142348754448396\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "PwordSpam, PwordHam, _, _ = computeProbabilities()\n",
    "print(\"Probability of 'possibilities' given target Spam: {}\".format(PwordSpam))\n",
    "print(\"Probability of 'possibilities' given target Ham: {}\\n\".format(PwordHam))\n",
    "\n",
    "for i in range(len(testFeat)):\n",
    "    if (testFeat[i][859] == 1):\n",
    "        if (testLabels[i] == 1):\n",
    "            accuracy += 1\n",
    "accuracy /= len(testFeat)\n",
    "print(\"Classifier test accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a difference in classifier accuracy from e to c and d given the difference in frequency of the words \"possibilities,'thanks' and 'money' in the training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of 'money,thanks,possibilities' given target Spam: [ 0.16414288  0.06853038  0.00252378]\n",
      "Probability of 'money,thanks,possibilities' given target Ham: [ 0.03032135  0.320137    0.00251838]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "PwordSpam, PwordHam, _, _ = computeProbabilities()\n",
    "print(\"Probability of 'money,thanks,possibilities' given target Spam: {}\".format(PwordSpam))\n",
    "print(\"Probability of 'money,thanks,possibilities' given target Ham: {}\\n\".format(PwordHam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier test accuracy: 0.6362153424193941\n"
     ]
    }
   ],
   "source": [
    "Yhat = []\n",
    "\n",
    "\n",
    "for i in range(len(testFeat)):\n",
    "    probSpam = 1\n",
    "    probHam = 1\n",
    "    if (testFeat[i][179] == 1):\n",
    "        probSpam *= PwordSpam[0]\n",
    "        probHam *= PwordHam[0]\n",
    "    if (testFeat[i][859] == 1):\n",
    "        probSpam *= PwordSpam[1]\n",
    "        probHam *= PwordHam[1]\n",
    "    if (testFeat[i][2211] == 1):\n",
    "        probSpam *= PwordSpam[2]\n",
    "        probHam *= PwordHam[2]\n",
    "    \n",
    "    if (probSpam >= probHam):\n",
    "        Yhat.append(1)\n",
    "    elif(probSpam < probHam):\n",
    "        Yhat.append(0)\n",
    "            \n",
    "for j in range(len(testFeat)):\n",
    "    if (Yhat[j] == testLabels[j]):\n",
    "        accuracy += 1\n",
    "accuracy /= len(testFeat)\n",
    "print(\"Classifier test accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of 'possibilities' given target Spam: [  1.09493302e-01   3.53620656e-01   6.45505727e-02 ...,   9.70685304e-05\n",
      "   9.70685304e-05   9.70685304e-05]\n",
      "Probability of 'possibilities' given target Ham: [ 0.07484638  0.32890098  0.0512743  ...,  0.00100735  0.00120882\n",
      "  0.00110809]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "\n",
    "PwordSpam, PwordHam, _, _ = computeProbabilities()\n",
    "print(\"Probability of 'possibilities' given target Spam: {}\".format(PwordSpam))\n",
    "print(\"Probability of 'possibilities' given target Ham: {}\\n\".format(PwordHam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier test accuracy: 0.9635231316725978\n"
     ]
    }
   ],
   "source": [
    "Yhat = []\n",
    "for i in range(len(testFeat)):\n",
    "    probSpam = 0\n",
    "    probHam = 0\n",
    "    for j in range(W):\n",
    "        if (testFeat[i][j] == 1):\n",
    "            probSpam += np.log(PwordSpam[j])\n",
    "            probHam += np.log(PwordHam[j])\n",
    "    \n",
    "    if (probSpam >= probHam):\n",
    "        Yhat.append(1)\n",
    "    elif(probSpam < probHam):\n",
    "        Yhat.append(0)\n",
    "\n",
    "for k in range(len(testLabels)):\n",
    "    if (Yhat[k] == testLabels[k]):\n",
    "        accuracy += 1\n",
    "accuracy /= len(testFeat)\n",
    "print(\"Classifier test accuracy: {}\".format(accuracy))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
